{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d72a9674",
   "metadata": {
    "id": "Ug-NsCoZViN8"
   },
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8bb48158",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas torch datasets transformers sentence-transformers requests tqdm nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3fd3adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from collections import Counter\n",
    "from tqdm.auto import tqdm\n",
    "import mmh3\n",
    "import requests\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c470c16",
   "metadata": {
    "id": "Q68EZtCmooq4"
   },
   "source": [
    "## Connect to Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4d5bf0",
   "metadata": {
    "id": "Oweyy_KjV_Y3"
   },
   "source": [
    "The hybrid vector index is currently not available in Pinecone python client. So, we will use the Pinecone REST API to communicate with the new index. The ```HybridPinecone``` class below gives you a similar interface to the python-client to communicate with the new index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ed602503",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridPinecone:\n",
    "    # initializes the HybridPinecone object\n",
    "    def __init__(self, api_key, environment):\n",
    "        # make environment, headers and project_id available across all the function within the class\n",
    "        self.environment = environment\n",
    "        self.headers = {'Api-Key': api_key}\n",
    "        # get project_id\n",
    "        res = requests.get(\n",
    "            f\"https://controller.{self.environment}.pinecone.io/actions/whoami\",\n",
    "            headers=self.headers\n",
    "        )\n",
    "        self.project_id = res.json()['project_name']\n",
    "        self.host = None\n",
    "\n",
    "    # creates an index in pinecone vector database\n",
    "    def create_index(self, index_name, dimension, metric, pod_type):\n",
    "        # index specification\n",
    "        params = {\n",
    "            'name': index_name,\n",
    "            'dimension': dimension,\n",
    "            'metric': metric,\n",
    "            'pod_type': pod_type\n",
    "        }\n",
    "        # sent a post request with the headers and parameters to pinecone database\n",
    "        res = requests.post(\n",
    "            f\"https://controller.{self.environment}.pinecone.io/databases\",\n",
    "            headers=self.headers,\n",
    "            json=params\n",
    "        )\n",
    "        # return the creation status\n",
    "        return res\n",
    "    \n",
    "    # get the project_id for the index and update self.host variable\n",
    "    def connect_index(self, index_name):\n",
    "        # set the self.host variable\n",
    "        self.host = f\"{index_name}-{self.project_id}.svc.{self.environment}.pinecone.io\"\n",
    "        res = self.describe_index_stats()\n",
    "        # return index related information as json\n",
    "        return res\n",
    "    \n",
    "    def describe_index(self, index_name):\n",
    "        # send a get request to pinecone database to get index description\n",
    "        res = requests.get(\n",
    "            f\"https://controller.{self.environment}.pinecone.io/databases/{index_name}\",\n",
    "            headers=self.headers\n",
    "        )\n",
    "        return res.json()\n",
    "\n",
    "    # returns description of the index\n",
    "    def describe_index_stats(self):\n",
    "        # send a get request to pinecone database to get index description\n",
    "        res = requests.get(\n",
    "            f\"https://{self.host}/describe_index_stats\",\n",
    "            headers=self.headers\n",
    "        )\n",
    "        # return the index description as json\n",
    "        return res.json()\n",
    "\n",
    "    # uploads the documents to pinecone database\n",
    "    def upsert(self, vectors):\n",
    "        # send a post request with vectors to pinecone database\n",
    "        res = requests.post(\n",
    "            f\"https://{self.host}/hybrid/vectors/upsert\",\n",
    "            headers=self.headers,\n",
    "            json={'vectors': vectors}\n",
    "        )\n",
    "        # return the http response status\n",
    "        return res\n",
    "\n",
    "    # searches pinecone database with the query\n",
    "    def query(self, query):\n",
    "        # sends a post request to hybrib vector index with the query dict\n",
    "        res = requests.post(\n",
    "            f\"https://{self.host}/hybrid/query\",\n",
    "            headers=self.headers,\n",
    "            json=query\n",
    "        )\n",
    "        # returns the result as json\n",
    "        return res.json()\n",
    "\n",
    "    # deletes an index in pinecone database\n",
    "    def delete_index(self, index_name):\n",
    "        # sends a delete request\n",
    "        res = requests.delete(\n",
    "            f\"https://controller.{self.environment}.pinecone.io/databases/{index_name}\",\n",
    "            headers=self.headers\n",
    "        )\n",
    "        # returns the http response status\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c470c16",
   "metadata": {
    "id": "Q68EZtCmooq4"
   },
   "source": [
    "## Create index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "eccb6f72",
   "metadata": {
    "id": "n83cvMOXuXcD"
   },
   "outputs": [],
   "source": [
    "# initialize an instance of HybridPinecone class\n",
    "pinecone = HybridPinecone(\n",
    "    api_key = \"1f136ea0-a50c-4af1-a9ad-93de37970fab\",  # app.pinecone.io\n",
    "    environment = \"us-west1-gcp\"\n",
    ")\n",
    "\n",
    "# choose a name for your index\n",
    "index_name = \"hybrid-search-demo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "73c508d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [201]>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the index\n",
    "pinecone.create_index(\n",
    "    index_name = index_name,\n",
    "    dimension = 384,\n",
    "    metric = \"dotproduct\",\n",
    "    pod_type = \"s1h\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aa165b",
   "metadata": {
    "id": "PWdW7PGnsvcU"
   },
   "source": [
    "Now we have created the hybrid vector index using the `\"s1h\"` hybrid `pod_type`. To connect to the index we must `wait until it is ready`, we can check it's status like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c29be891",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bi5Qik1vsvcU",
    "outputId": "7d2caeef-883b-4c83-da42-328f682c54da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'database': {'name': 'hybrid-search-demo',\n",
       "  'index_type': 'approximated',\n",
       "  'metric': 'dotproduct',\n",
       "  'dimension': 384,\n",
       "  'replicas': 1,\n",
       "  'shards': 1,\n",
       "  'pods': 1,\n",
       "  'pod_type': 's1h',\n",
       "  'index_config': {'approximated': {'k_bits': 512}}},\n",
       " 'status': {'waiting': [],\n",
       "  'crashed': [],\n",
       "  'host': 'hybrid-search-demo-94a860f.svc.us-west1-gcp.pinecone.io',\n",
       "  'port': 433,\n",
       "  'state': 'Ready',\n",
       "  'ready': True}}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone.describe_index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59ecce3",
   "metadata": {
    "id": "OiiXWh2ghdvs"
   },
   "source": [
    "If the `state` is `'Ready'` we can continue and connect to the index like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c25e1254",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-gZK5K_-wIMn",
    "outputId": "7f4e3426-0918-4cb1-cf31-6947638a5bf2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespaces': {}, 'dimension': 384, 'indexFullness': 0, 'totalVectorCount': 0}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone.connect_index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8470b6e5",
   "metadata": {
    "id": "jfQ8_Uqf_f-8"
   },
   "source": [
    "## Load Dataset\n",
    "\n",
    "We will use a json file containing a web crawl of pinecone.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "47436f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"Pinecone_io_Webcrawl.json\")\n",
    "\n",
    "ids = [] # id\n",
    "titles = [] # title\n",
    "contents = [] # content\n",
    "urls = [] # url\n",
    "boosts = [] # boost\n",
    "blob_texts = [] # derived from titles, bodies, and urls\n",
    "\n",
    "# Process fields to be used as metadata later\n",
    "for doc in df.response.docs:\n",
    "\n",
    "    title = str(doc.get('title'))\n",
    "    titles.append(title)\n",
    "\n",
    "    content = str(doc.get('content'))\n",
    "    contents.append(content[:500])\n",
    "\n",
    "    url = str(doc.get('url'))\n",
    "    urls.append(url)\n",
    "\n",
    "    boost = str(doc.get('boost'))\n",
    "    boosts.append(boost)\n",
    "\n",
    "    # Blob text will be used to generate the sparse and dense vectors\n",
    "    blob_text =  str(doc.get('title')) + ' ' + str(doc.get('content')) + ' ' + str(doc.get('url'))\n",
    "    blob_texts.append(blob_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9090a1",
   "metadata": {
    "id": "PyuqZHg_j22O"
   },
   "source": [
    "## Sparse and Dense Vector Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7c4b5355",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "d53abbf94f4940f6a5f8fee19287fcda",
      "4002881c1c7f4f15a16a26a49dcc8215",
      "f22e1a1391244f0c9ca035a9afa6a759",
      "37b48fe5f5a4434b989ade8ae01bfae6",
      "820dc52d19004802812f042529f1ab63",
      "d2e5c122610f4c26a2459208dc3a7e27",
      "91e1e2a2a6604412afe93a54d9464520",
      "6d37cb5c144846cf96f3ec8f2d317ec2",
      "2cee7bd96f984af9ae830d33569c2b75",
      "36da60255be6456d82e05c55408549c0",
      "9d94f23fc59945a79896415ca5dc7200",
      "9bf28f6509f84a7ea0395e25c9464b1d",
      "572ae4cb995e4eb889c97402436c4a14",
      "ff5f803b97234fc79f34809b616d4ba2",
      "a4f4c5dd1175485e91f4fa5a9e536d2c",
      "db32c27ce80d4de39e7a897613ab92e6",
      "b3eeda2cbddc4cd1915adee69e3db77f",
      "6f5c9b4180054fcebdf74a5c9f4e1328",
      "65f328726dc6492fb29df53da6ab02a6",
      "95305e6dcb544ceba78af0ee55688852",
      "4720331260eb4905b4bd45bf9aff4be4",
      "7de95b090f9f4178985feee7f35edb28",
      "260a2c3a78b3441e820522f4a4c04da8",
      "c2249564ce77497da3cfb1d9f42d7dcf",
      "60bc87fc20304983a3e574f8a36eaaed",
      "b094f99816004968b2273029a0d19cb7",
      "5c635821a85042d183eca9d842ef08d9",
      "55e240e2cdad4ad6a750d92b89ae2149",
      "48bd9d63184c4e228ac42c7337f37de2",
      "a375ae1e16b64390950ef76791486562",
      "e0c1273ac30849839e1a8fd4f6cdbf39",
      "908646d92b3e4e87ade563902f44496c",
      "3cec1dbc873b4483a231c7fbe50d60f0",
      "d4863fddae334c9f94030bacc37750d4",
      "06f81cf42e194e88b6f34ee490a89aff",
      "bf9164e0b39440359336c3fe8927be74",
      "5e30ff2ce7c84738b8021fbb48321870",
      "d5d09b5d397a4c238b29a7520e3ef26f",
      "4b87dcdab5aa4f248285975e530c303d",
      "b62253243f0246cfb3a82e4999bd7801",
      "ed1870107bb4437389775e83f29704a3",
      "5f8b8766c5fd41a7bbdfb8915dcb20cd",
      "ce1198d5237f4887be6066dd5f4ad73e",
      "ca931bc257a54695a8494968cfa3c775"
     ]
    },
    "id": "Zka805CX_f-9",
    "outputId": "7dd3dd50-5f97-4056-b77d-b5bf9c26377e"
   },
   "outputs": [],
   "source": [
    "# load a sentence transformer model from huggingface\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# create a tokenizer\n",
    "class Tokenizer:\n",
    "  def __init__(self):\n",
    "    self.stemmer = SnowballStemmer('english')\n",
    "\n",
    "  def encode(self, text):\n",
    "    words = [self.stemmer.stem(word) for word in word_tokenize(text)]\n",
    "    ids = [mmh3.hash(word, signed=False) for word in words]\n",
    "    return dict(Counter(ids))\n",
    "\n",
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "96ff087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_vectors = []\n",
    "dense_vectors = []\n",
    "\n",
    "for blob in blob_texts:\n",
    "    sparse_vectors.append(tokenizer.encode(str(blob)))\n",
    "    dense_vectors.append(model.encode([blob], normalize_embeddings=True).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "84ef06bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'https://www.pinecone.io/learn/', 'title': 'Learning Center | Pinecone', 'content': 'Learning Center | Pinecone\\nPricing\\nDocs\\nLearn\\nLearning Center\\nCommunity\\nCompany\\nAbout\\nCareers\\nPartners\\nTrust & Security\\nContact\\nLog In\\nSign Up Free\\nPricing\\nDocs\\nLearn\\nCommunity\\nCompany\\nCareers\\nPartners\\nTrust & Security\\nContact\\nLog In\\nCreate Account\\nToggle menu\\nLearn to Love Working with Vector Embeddings\\nUnlock the power of machine learning. Our guides will help you conquer vector embeddings and build better applications.\\nOur Series\\nNatural Language Processing for Semantic Search\\nLearn how to bu', 'boost': '2.0329747'}\n"
     ]
    }
   ],
   "source": [
    "# Build metadata\n",
    "meta = []\n",
    "for url, title, content, boost in zip(urls,titles,contents,boosts):\n",
    "    metavalue = {'url':url,'title':title,'content':content,'boost':boost}\n",
    "    meta.append(metavalue)\n",
    "\n",
    "print(meta[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dacfa1",
   "metadata": {
    "id": "wph64ujXrhrp"
   },
   "source": [
    "## Upsert Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33056c98",
   "metadata": {
    "id": "oX99CnOroEq0"
   },
   "source": [
    "Now we can go ahead and generate sparse and dense vectors for the full dataset and upsert them along with the metadata to the new hybrid index. We can do that easily as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "796b3a7a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118,
     "referenced_widgets": [
      "7a01cfb8ac7c4d2293efca7f8030f407",
      "550a296587d24a3f867f45b09273648c",
      "b8e4d284fc124a6eb75999df4bff1bc5",
      "f396028be4d845349e542efde6fee7f2",
      "1f173bb2a3cf4b3396124f62a0964d85",
      "7f33ae1dce5241b9b4aa19368a00de3a",
      "1e7c98d2ac40410d84514111fe61dcc1",
      "3964c2274b6746f8aa0a79ec8a36c338",
      "6c5e8672edab4fff968943bdec9154fc",
      "d98293d4f95042f69a4db00fcd3b60fe",
      "172a255a494e4eb8a012d49c3259c21c"
     ]
    },
    "id": "vcM5h0T1_f-_",
    "outputId": "d6a55761-a405-4bde-b949-fb4cdb59ab05"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d5803a701b411687c58a00a8600013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'namespaces': {'': {'vectorCount': 32}},\n",
       " 'dimension': 384,\n",
       " 'indexFullness': 0,\n",
       " 'totalVectorCount': 32}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for i in tqdm(range(0, len(blob_texts), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(i+batch_size, len(blob_texts))\n",
    "    # create unique IDs\n",
    "    ids = [str(x) for x in range(i, i_end)]\n",
    "\n",
    "    vectors = []\n",
    "\n",
    "    for id, sparse, dense, metadata in zip(ids[i:i_end], sparse_vectors[i:i_end], dense_vectors[i:i_end], meta[i:i_end]):\n",
    "        vectors.append({\n",
    "            'id': id,\n",
    "            'sparse_values': sparse,\n",
    "            'values': dense,\n",
    "            'metadata': metadata\n",
    "        })\n",
    "\n",
    "    # upload the documents to the new hybrid index\n",
    "    pinecone.upsert(vectors)\n",
    "\n",
    "# show index description after uploading the documents\n",
    "pinecone.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434456da",
   "metadata": {
    "id": "ir1n8ABfqbV-"
   },
   "source": [
    "## Querying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7fbcfb",
   "metadata": {
    "id": "vv24_cjVrVKz"
   },
   "source": [
    "Now we can query the index, providing the sparse and dense vectors of a question, along with a weight for keyword relevance (“alpha”). `Alpha=1` will provide a purely semantic-based search result and `alpha=0` will provide a purely keyword-based result equivalent to BM25. The default value is `0.5`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61acb59",
   "metadata": {
    "id": "IedLiNIEqdWi"
   },
   "source": [
    "Let's write a helper function to execute queries and after that run some queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9bf86e47",
   "metadata": {
    "id": "HuIoyi6Trwqc"
   },
   "outputs": [],
   "source": [
    "def hybrid_query(question, top_k, alpha):\n",
    "    # convert the question into a sparse vector\n",
    "    sparse_vec = generate_sparse_vectors([question])\n",
    "    # convert the question into a dense vector\n",
    "    dense_vec = model.encode([question]).tolist()\n",
    "    # set the query parameters to send to pinecone\n",
    "    query = {\n",
    "      \"topK\": top_k,\n",
    "      \"vector\": dense_vec,\n",
    "      \"sparseVector\": sparse_vec[0],\n",
    "      \"alpha\": alpha,\n",
    "      \"includeMetadata\": True\n",
    "    }\n",
    "    # query pinecone with the query parameters\n",
    "    result = pinecone.query(query)\n",
    "    # return search results as json\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d6ff1c65",
   "metadata": {
    "id": "iszWr04qvONn"
   },
   "outputs": [],
   "source": [
    "question = \"are you in us-east-2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cb26e8",
   "metadata": {
    "id": "TBjad1-cvRlA"
   },
   "source": [
    "First, we will do a pure semantic search by setting the alpha value as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fc6c1e7c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jQkFj1b_qjfx",
    "outputId": "fc876ac3-347c-46c9-b779-f1117f85f4db"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_sparse_vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [133], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hybrid_query(question, top_k\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, alpha\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn [131], line 3\u001b[0m, in \u001b[0;36mhybrid_query\u001b[0;34m(question, top_k, alpha)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhybrid_query\u001b[39m(question, top_k, alpha):\n\u001b[1;32m      2\u001b[0m     \u001b[39m# convert the question into a sparse vector\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     sparse_vec \u001b[39m=\u001b[39m generate_sparse_vectors([question])\n\u001b[1;32m      4\u001b[0m     \u001b[39m# convert the question into a dense vector\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     dense_vec \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mencode([question])\u001b[39m.\u001b[39mtolist()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_sparse_vectors' is not defined"
     ]
    }
   ],
   "source": [
    "hybrid_query(question, top_k=1, alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65757719",
   "metadata": {
    "id": "88o5Cn-FwF-1"
   },
   "source": [
    "The most relevant result from above is the second document with id 711. Now let's try with an alpha value of 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334d8de6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HjXgq7OQwmfM",
    "outputId": "daee78ed-3b7e-4c52-f95f-522408c05dc9"
   },
   "outputs": [],
   "source": [
    "hybrid_query(question, top_k=1, alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90fecbc",
   "metadata": {
    "id": "eqZ93O95w2oe"
   },
   "source": [
    "The most relevant document is now ranked the highest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba4e052",
   "metadata": {
    "id": "1YY3hiL3xNQ5"
   },
   "source": [
    "# Delete the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a0db26",
   "metadata": {
    "id": "DnGtG5iaUArB"
   },
   "outputs": [],
   "source": [
    "#pinecone.delete_index(\"hybrid-search-demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f297406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinecone",
   "language": "python",
   "name": "pinecone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
